---
chapter: "learning-I"
author: ""
difficulty: "Hard"
date: 2020-07-14 
version: 0.1
tags: [first, second, third]
id: dog-cost-oven
---

```{r dog-cost-oven-default, include = FALSE, warning = FALSE}
mdsr2exercises::setup()
library(tidyverse)
```

TITLE GOES HERE: The ability to get a good night's sleep is correlated with many positive health outcomes. The `NHANES` data set contains a binary variable `SleepTrouble` that indicates whether each person has trouble sleeping. 


a. For each of the following models:

    -  Build a classifier for SleepTrouble
    -  Report its effectiveness on the NHANES training data
    -  Make an appropriate visualization of the model
    -  Interpret the results. What have you learned about people's sleeping habits?
  
You may use whatever variable you like, except for `SleepHrsNight`.

  -  Null model
  -  Logistic regression
  -  Decision tree
  -  Random forest
  -  Neural network
  -  Naive Bayes
  -  $k$-NN


<!--begin-answer-->

First we do some data cleaning. In this case, 22.3% of the responses for `SleepTrouble` were `NA`'s. We choose to omit those responses. 

```{r }
library(mdsr)
library(NHANES)
library(rpart)
NHANES %>%
  group_by(SleepTrouble) %>%
  summarize(N = n())

NHANES_good <- NHANES %>%
  filter(!is.na(SleepTrouble))
```

Among those that did respond, about one quarter reported having troubling sleeping. 

```{r, warning=FALSE}
NHANES_good %>%
  summarize(N = n(), sleep_trouble = sum(SleepTrouble == "Yes")) %>%
  mutate(sleep_pct = sleep_trouble / N)

confusion_null <- NHANES_good %>%
  select(SleepTrouble) %>%
  mutate(sleep_trouble_hat = 0) %>%
  table()

confusion_null

sum(diag(confusion_null)) / sum(confusion_null)
```

Thus, the effectiveness of the null model is `r round(sum(diag(confusion_null)) / sum(confusion_null), 4)`. 

We next fit a decision tree to the explanatory variables except for `SleepHrsNight`. 

```{r, warning=FALSE}
tree <- rpart(SleepTrouble ~ . - SleepHrsNight, data = NHANES_good)

confusion_tree <- NHANES_good %>%
  mutate(sleep_trouble_hat = predict(tree, type = "class")) %>%
  select(SleepTrouble, sleep_trouble_hat) %>%
  table()

sum(diag(confusion_tree)) / sum(confusion_tree)
```

The effectiveness of the decision tree is `r round(sum(diag(confusion_tree)) / sum(confusion_tree), 4)`, which only slightly exceeds that of the null model. 

The tree itself reveals that participants with 7 or more days of bad physical health *and* 6 or more days of mental health are classified as having sleep trouble. All other participants are classified as not having sleep trouble. 

```{r }
tree
```

This visualization tiles the plane with the model outputs, and then overlays the observed data. We make use of the `modelr` package in this example. 

```{r plottree, message=FALSE, , warning=FALSE}
tree2 <- rpart(SleepTrouble ~ DaysMentHlthBad + DaysPhysHlthBad,
  data = NHANES_good
)
library(modelr)
grid <- NHANES %>%
  data_grid(DaysMentHlthBad,
    DaysPhysHlthBad = seq_range(DaysPhysHlthBad, by = 1)
  ) %>%
  mutate(sleep_trouble_hat = predict(tree2, newdata = ., type = "class"))

ggplot(grid, aes(
  x = DaysMentHlthBad, y = DaysPhysHlthBad,
  fill = sleep_trouble_hat
)) +
  geom_tile(alpha = 0.2) +
  geom_ref_line(h = 6.5) +
  geom_ref_line(v = 5.5) +
  geom_point(
    data = NHANES_good,
    aes(color = SleepTrouble, fill = SleepTrouble),
    position = "jitter", alpha = 0.5
  )
```


<!--end-answer-->

b. Repeat the previous exercise, but now use the quantitative response variable `SleepHrsNight`. Build and interpret the following models:

  -  Null model
  -  Multiple regression
  -  Regression tree
  -  Random forest
  -  Ridge regression
  -  LASSO


<!--begin-answer-->

We try a random forest. The story is a bit different here in that `BMI`and `Age` seem to have more predictive value for the number of hours slept. 

```{r message=FALSE, warning=FALSE}
library(randomForest)
tree_reg <- randomForest(SleepHrsNight ~ Gender + Age + BMI +
  Race1 + Education + MaritalStatus + SmokeNow +
  PhysActiveDays + DaysPhysHlthBad + DaysMentHlthBad,
data = NHANES, na.action = na.exclude,
ntree = 201, mtry = 3
)
tree_reg
importance(tree_reg) %>% 
  as_tibble(rownames = "variable") %>%
  arrange(desc(IncNodePurity))
```
<!--end-answer-->



c. Repeat either of the previous exercises, but this time first separate the `NHANES` data set uniformly at random into 75% training and 25% testing sets. Compare the effectiveness of each model on training vs. testing data. 

<!--begin-answer-->
The `modelr` package makes this easier. First we generate the training and testing sets.

```{r, , warning=FALSE}
library(tidymodels)
set.seed(364)
NHANES_split <- NHANES_good %>%
  initial_split(prop = 0.75)

NHANES_train <- NHANES_split  %>%
  training()

NHANES_test <- NHANES_split  %>%
  testing()
```

Next, we fit a decision tree model to the training set. 

```{r }
tree_train <- rpart(SleepTrouble ~ DaysMentHlthBad + DaysPhysHlthBad,
  data = NHANES_train
)

tree_train
```

Then we evaluate that model on the testing set. 

```{r, warning=FALSE}
confusion_test <- NHANES_test %>%
  mutate(sleep_trouble_hat = predict(tree_train, newdata = ., type = "class")) %>%
  select(SleepTrouble, sleep_trouble_hat) %>%
  table()

sum(diag(confusion_test)) / sum(confusion_test)
```

<!--end-answer-->


d. Repeat the first exercise in part (a), but for the variable `PregnantNow`. What did you learn about who is pregnant? 


<!--begin-answer-->
```{r, message = FALSE, warning=FALSE}
NHANES %>%
  group_by(PregnantNow) %>%
  summarize(N = n())

NHANES_good <- NHANES %>%
  filter(!is.na(PregnantNow))

NHANES_good %>%
  select(PregnantNow, Gender) %>%
  table()
```

Note that only female respondents are potentially pregnant. 

```{r }
rpart(PregnantNow ~ ., data = NHANES_good)
```

Not surprisingly, the first split in the decision tree occurs for those with high testosterone are considered pregnant. For those with low testosterone, an examination of their urine (flow for those with low blood pressure, volume for those with high blood pressure) determines their classification. We start to get some clues about how home pregnancy tests---which analyze one's urine---work.  

<!--end-answer-->


